# æµå¼å“åº”å®ç°æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†åŸºäº Vercel Edge Function å’Œ OpenAI GPT çš„æµå¼å“åº”åŠŸèƒ½ï¼Œæä¾›å®æ—¶çš„ AI å¯¹è¯ä½“éªŒã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. æŠ€æœ¯æ ˆ
- **åç«¯**: Vercel Edge Functions (Next.js App Router)
- **å‰ç«¯**: React + TypeScript + Tailwind CSS
- **AI æœåŠ¡**: OpenAI GPT API
- **æµå¼åè®®**: Server-Sent Events (SSE)

### 2. æ ¸å¿ƒç»„ä»¶

```
app/api/chat-stream/route.ts    # Edge Function API è·¯ç”±
hooks/use-streaming-chat.ts     # æµå¼èŠå¤© Hook
components/chat-streaming.tsx   # èŠå¤©ç•Œé¢ç»„ä»¶
app/streaming-demo/page.tsx     # æ¼”ç¤ºé¡µé¢
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

åœ¨ `.env.local` æ–‡ä»¶ä¸­æ·»åŠ  OpenAI API å¯†é’¥ï¼š

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

### 2. å¯åŠ¨å¼€å‘æœåŠ¡å™¨

```bash
pnpm dev
```

### 3. è®¿é—®æ¼”ç¤ºé¡µé¢

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š`http://localhost:3000/streaming-demo`

## ğŸ”§ æ ¸å¿ƒå®ç°

### 1. Edge Function API (app/api/chat-stream/route.ts)

```typescript
export const runtime = 'edge'; // å¯ç”¨ Edge Runtime

export async function POST(request: NextRequest) {
  // 1. è§£æè¯·æ±‚å‚æ•°
  const { messages, model, temperature, max_tokens } = await request.json();
  
  // 2. è°ƒç”¨ OpenAI API (å¯ç”¨æµå¼)
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model,
      messages,
      stream: true, // å…³é”®ï¼šå¯ç”¨æµå¼å“åº”
    }),
  });

  // 3. åˆ›å»ºæµå¼å“åº”
  const stream = new ReadableStream({
    async start(controller) {
      const reader = response.body?.getReader();
      // å¤„ç†æµå¼æ•°æ®å¹¶è½¬å‘ç»™å®¢æˆ·ç«¯
    }
  });

  return new NextResponse(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache, no-transform',
      'Connection': 'keep-alive',
    },
  });
}
```

### 2. è‡ªå®šä¹‰ Hook (hooks/use-streaming-chat.ts)

```typescript
export function useStreamingChat(options: StreamingChatOptions = {}) {
  const [state, setState] = useState<StreamingState>({
    messages: [],
    currentResponse: '',
    isStreaming: false,
    error: null,
  });

  const sendMessage = useCallback(async (content: string) => {
    // 1. å‘é€è¯·æ±‚åˆ° Edge Function
    const response = await fetch('/api/chat-stream', {
      method: 'POST',
      body: JSON.stringify({ messages, model, temperature }),
      signal: abortController.signal,
    });

    // 2. å¤„ç†æµå¼å“åº”
    const reader = response.body?.getReader();
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      // è§£æå¹¶æ›´æ–° UI
      const chunk = decoder.decode(value);
      // å¤„ç† SSE æ ¼å¼æ•°æ®
    }
  }, []);

  return {
    messages,
    currentResponse,
    isStreaming,
    error,
    sendMessage,
    stopStreaming,
    clearMessages,
    retryLastMessage,
  };
}
```

### 3. React ç»„ä»¶ (components/chat-streaming.tsx)

```typescript
export default function ChatStreaming() {
  const {
    messages,
    currentResponse,
    isStreaming,
    sendMessage,
    stopStreaming,
  } = useStreamingChat({
    model: 'gpt-4',
    temperature: 0.7,
    systemMessage: 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹',
  });

  return (
    <div className="chat-container">
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <div className="messages">
        {messages.map(message => (
          <MessageBubble key={message.timestamp} message={message} />
        ))}
        
        {/* å®æ—¶æ˜¾ç¤ºæµå¼å“åº” */}
        {currentResponse && (
          <StreamingMessage content={currentResponse} />
        )}
      </div>

      {/* è¾“å…¥åŒºåŸŸ */}
      <ChatInput 
        onSend={sendMessage}
        onStop={stopStreaming}
        isStreaming={isStreaming}
      />
    </div>
  );
}
```

## ğŸ¯ å…³é”®ç‰¹æ€§

### 1. å®æ—¶æµå¼å“åº”
- ä½¿ç”¨ Server-Sent Events (SSE) åè®®
- é€å­—ç¬¦æ˜¾ç¤º AI å›å¤
- æ”¯æŒä¸­æ–­å’Œé‡è¯•

### 2. ç”¨æˆ·ä½“éªŒä¼˜åŒ–
- è‡ªåŠ¨æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
- åŠ è½½çŠ¶æ€æŒ‡ç¤º
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- æ”¯æŒé”®ç›˜å¿«æ·é”®

### 3. æ€§èƒ½ä¼˜åŒ–
- Edge Runtime é™ä½å»¶è¿Ÿ
- æµå¼ä¼ è¾“å‡å°‘é¦–å­—èŠ‚æ—¶é—´
- å®¢æˆ·ç«¯çŠ¶æ€ç®¡ç†ä¼˜åŒ–

## ğŸ” æ•°æ®æµç¨‹

```
ç”¨æˆ·è¾“å…¥ â†’ Reactç»„ä»¶ â†’ useStreamingChat Hook â†’ Edge Function API
                                                        â†“
OpenAI API â† HTTPè¯·æ±‚ â† æ„å»ºæ¶ˆæ¯å†å² â† å‚æ•°éªŒè¯ â† è¯·æ±‚è§£æ
    â†“
æµå¼å“åº” â†’ Edge Function â†’ ReadableStream â†’ SSEæ ¼å¼ â†’ å®¢æˆ·ç«¯
                                                        â†“
è§£ææ•°æ® â†’ æ›´æ–°çŠ¶æ€ â†’ é‡æ–°æ¸²æŸ“ â†’ å®æ—¶æ˜¾ç¤º â†’ ç”¨æˆ·çœ‹åˆ°ç»“æœ
```

## ğŸ› ï¸ é…ç½®é€‰é¡¹

### API é…ç½®
```typescript
interface ChatRequest {
  messages: ChatMessage[];
  model?: string;           // é»˜è®¤: 'gpt-4'
  temperature?: number;     // é»˜è®¤: 0.7
  max_tokens?: number;      // é»˜è®¤: 2000
}
```

### Hook é…ç½®
```typescript
interface StreamingChatOptions {
  model?: string;
  temperature?: number;
  max_tokens?: number;
  systemMessage?: string;   // ç³»ç»Ÿæç¤ºè¯
}
```

## ğŸš¨ é”™è¯¯å¤„ç†

### 1. ç½‘ç»œé”™è¯¯
- è‡ªåŠ¨é‡è¯•æœºåˆ¶
- è¿æ¥ä¸­æ–­æ¢å¤
- è¶…æ—¶å¤„ç†

### 2. API é”™è¯¯
- OpenAI API é™æµå¤„ç†
- è®¤è¯å¤±è´¥æç¤º
- æ¨¡å‹ä¸å¯ç”¨å¤„ç†

### 3. å®¢æˆ·ç«¯é”™è¯¯
- è§£æé”™è¯¯å®¹é”™
- çŠ¶æ€åŒæ­¥ä¿æŠ¤
- å†…å­˜æ³„æ¼é˜²æŠ¤

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### å“åº”æ—¶é—´
- é¦–å­—èŠ‚æ—¶é—´: < 500ms
- æµå¼å»¶è¿Ÿ: < 100ms
- å®Œæ•´å“åº”: æ ¹æ®å†…å®¹é•¿åº¦

### èµ„æºä½¿ç”¨
- Edge Function å†·å¯åŠ¨: < 200ms
- å†…å­˜ä½¿ç”¨: < 50MB
- å¹¶å‘æ”¯æŒ: 1000+ è¿æ¥

## ğŸ”§ éƒ¨ç½²é…ç½®

### Vercel éƒ¨ç½²
```json
{
  "functions": {
    "app/api/chat-stream/route.ts": {
      "runtime": "edge"
    }
  }
}
```

### ç¯å¢ƒå˜é‡
```bash
OPENAI_API_KEY=sk-...
NODE_ENV=production
```

## ğŸ§ª æµ‹è¯•

### å•å…ƒæµ‹è¯•
```bash
pnpm test hooks/use-streaming-chat.test.ts
```

### é›†æˆæµ‹è¯•
```bash
pnpm test:integration api/chat-stream
```

### æ€§èƒ½æµ‹è¯•
```bash
pnpm test:performance streaming
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ç”¨æ³•
```typescript
import { useStreamingChat } from '@/hooks/use-streaming-chat';

function MyChat() {
  const { sendMessage, messages, isStreaming } = useStreamingChat();
  
  return (
    <div>
      {messages.map(msg => <div key={msg.timestamp}>{msg.content}</div>)}
      <button onClick={() => sendMessage('Hello!')}>
        Send
      </button>
    </div>
  );
}
```

### é«˜çº§é…ç½®
```typescript
const chat = useStreamingChat({
  model: 'gpt-4-turbo',
  temperature: 0.3,
  systemMessage: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯é¡¾é—®',
});
```

## ğŸ”„ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-01-21)
- âœ… å®ç°åŸºç¡€æµå¼å“åº”åŠŸèƒ½
- âœ… æ·»åŠ  Edge Function API
- âœ… åˆ›å»º React Hook å’Œç»„ä»¶
- âœ… å®Œå–„é”™è¯¯å¤„ç†æœºåˆ¶
- âœ… ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯: `git checkout -b feature/streaming-enhancement`
3. æäº¤æ›´æ”¹: `git commit -m 'Add streaming feature'`
4. æ¨é€åˆ†æ”¯: `git push origin feature/streaming-enhancement`
5. åˆ›å»º Pull Request

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ LICENSE æ–‡ä»¶